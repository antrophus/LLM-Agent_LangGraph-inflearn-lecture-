{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "\n",
    "# ## RAG 구성 해서 사용자의 질문이 들어오면 문서를 기반으로 검색을 하고 LLM에게 전달하는 것을 구성해보자.\n",
    "#  - retrieve를 해줄 노드를 만들어보자.\n",
    "#  - document를 읽어와서 적당한 사이즈로 잘라주는 작업이 필요하다.\n",
    "\n",
    "# ## 라이브러리 설치\n",
    "#  - pypdf : pdf 파일을 읽어오기 위한 라이브러리\n",
    "#  - langchain-community : langchain 라이브러리의 커뮤니티 라이브러리\n",
    "#  - langchain-text-splitters : 문서를 잘라주는 라이브러리\n",
    "\n",
    "%pip install -qU pypdf langchain-community langchain-text-splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 읽어오는 노드를 만들어보자. / langchain_community 공식 문서의 예제를 그대로 사용해보자.\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_file_path = './income_tax.pdf'\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages를 출력해보자. 쪽수별로 쪼개 놓았다.\n",
    "# pages\n",
    "\n",
    "# 55조를 출력해보자.\n",
    "pages[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "\n",
    "# # 표가 없이 다음으로 넘어가 버린다. ※langchain에서 기본으로 제공하는 PDF로더는 PDF 파일 안의 이미지를 파싱하지 못한다. \n",
    "#  - 따라서 이미지를 보고 싶으면 다른 라이브러리를 설치 해야 한다. \n",
    "#  - 다른 방법은 chat-gpt를 활용해서 \"제 55조의 테이블을 파싱해주세요\" 라고 질문을 해서 테이블을 파싱해주는 방법이 있다.\n",
    "#  - 그런데 모든 문서에 대해서 일일이 전처리를 할 수 없다. 따라서 이미지를 파싱할 수 있는 라이브러리를 설치해야 한다.\n",
    "#  - 강사가 추천하는 라이브러리는 파이썬 패키지 중 하나인 zerox이다. LLM을 활용해서 OCR을 돌려서 문서를 인식하는 패키지이다.\n",
    "#  - github.com/getomni-ai/zerox\n",
    "%pip install -q py-zerox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 gemini 모델을 사용하기 위해서 환경변수를 불러와야 한다.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드를 그냥 돌리면 에러가 난다. asyncio를 돌릴 때 이벤트루프가 없어야 하는데 notebook이 디폴트로뭔가 돌리는게 있어서 에러가 난다다.\n",
    "# 따라서 아래 코드를 돌리기 위해서는 패키지를 설치해야 한다.\n",
    "\n",
    "%pip install -q nest_asyncio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "\n",
    "# ## 추가 설치 해야 할 패키지(강사는 안함: 애플은 필요 없는 패키지 같음)\n",
    "# # Poppler 설치: Poppler(https://github.com/oschwartz10612/poppler-windows/releases/download/v24.08.0-0/Release-24.08.0-0.zip)를 다운로드하여 설치합니다. 운영체제에 맞는 Poppler 바이너리를 다운로드하여 압축을 풀고 적절한 위치에 저장합니다. \n",
    "#  - (Windows의 경우, bin 폴더의 경로를 기억해두세요.)\n",
    "# # 환경 변수 설정 (Windows): (1) 시스템 환경 변수 편집기(검색창에 \"환경 변수\" 검색)를 엽니다.\n",
    "# #                          (2) \"시스템 속성\" 창에서 \"환경 변수\" 버튼을 클릭합니다.\n",
    "# #                          (3) \"시스템 변수\" 섹션에서 \"Path\" 변수를 선택하고 \"편집\" 버튼을 클릭합니다.\n",
    "# #                          (4) \"새로 만들기\" 버튼을 클릭하고 Poppler bin 폴더의 경로를 추가합니다. (예: C:\\path\\to\\poppler-x.xx.x\\bin)\n",
    "# #                          (5) 모든 창을 닫고 변경 사항을 저장합니다.\n",
    "# #                          (6) 터미널 또는 IDE 재시작: 환경 변수 변경 사항이 적용되도록 터미널 또는 IDE를 재시작합니다.\n",
    "\n",
    "# 예제는 github에서 그대로 복사해 오면 된다.\n",
    "# LightLLM 이라는 래퍼를 사용해서 OCR을 돌리기 때문에 모델 이름과 환경변수를 주면 상용 LLM을 쓸 수 있다.\n",
    "# 여기서는 google-gemini-1.5-flash-001 이라는 모델을 사용하므로 다른 코드들은 삭제한다.\n",
    "\n",
    "from pyzerox import zerox\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "### Model Setup (Use only Vision Models) Refer: https://docs.litellm.ai/docs/providers ###\n",
    "\n",
    "## placeholder for additional model kwargs which might be required for some models\n",
    "kwargs = {}\n",
    "\n",
    "## system prompt to use for the vision model\n",
    "custom_system_prompt = None\n",
    "\n",
    "# to override\n",
    "# custom_system_prompt = \"For the below pdf page, do something..something...\" ## example\n",
    "\n",
    "# ###################### Example for OpenAI ######################\n",
    "# model = \"gpt-4o-mini\" ## openai model\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\" ## your-api-key\n",
    "\n",
    "\n",
    "# ###################### Example for Azure OpenAI ######################\n",
    "# model = \"azure/gpt-4o-mini\" ## \"azure/<your_deployment_name>\" -> format <provider>/<model>\n",
    "# os.environ[\"AZURE_API_KEY\"] = \"\" # \"your-azure-api-key\"\n",
    "# os.environ[\"AZURE_API_BASE\"] = \"\" # \"https://example-endpoint.openai.azure.com\"\n",
    "# os.environ[\"AZURE_API_VERSION\"] = \"\" # \"2023-05-15\"\n",
    "\n",
    "\n",
    "###################### Example for Gemini ######################\n",
    "model = \"gemini/gemini-2.0-flash-exp\" ## \"gemini/<gemini_model>\" -> format <provider>/<model>\n",
    "# os.environ['GEMINI_API_KEY'] = \"\" # your-gemini-api-key  : 환경변수는 따로 불러오면 되므로 여기선 안쓴다.\n",
    "\n",
    "\n",
    "# ###################### Example for Anthropic ######################\n",
    "# model=\"claude-3-opus-20240229\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"\" # your-anthropic-api-key\n",
    "\n",
    "# ###################### Vertex ai ######################\n",
    "# model = \"vertex_ai/gemini-1.5-flash-001\" ## \"vertex_ai/<model_name>\" -> format <provider>/<model>\n",
    "# ## GET CREDENTIALS\n",
    "# ## RUN ##\n",
    "# # !gcloud auth application-default login - run this to add vertex credentials to your env\n",
    "# ## OR ##\n",
    "# file_path = 'path/to/vertex_ai_service_account.json'\n",
    "\n",
    "# # Load the JSON file\n",
    "# with open(file_path, 'r') as file:\n",
    "#     vertex_credentials = json.load(file)\n",
    "\n",
    "# # Convert to JSON string\n",
    "# vertex_credentials_json = json.dumps(vertex_credentials)\n",
    "\n",
    "# vertex_credentials=vertex_credentials_json\n",
    "\n",
    "# ## extra args\n",
    "# kwargs = {\"vertex_credentials\": vertex_credentials}\n",
    "\n",
    "# ###################### For other providers refer: https://docs.litellm.ai/docs/providers ######################\n",
    "\n",
    "# Define main async entrypoint\n",
    "async def main():\n",
    "    file_path = \"./pixel-nvidia.pdf\" ## local filepath and file URL supported\n",
    "\n",
    "    ## process only some pages or all\n",
    "    select_pages = None ## None for all, but could be int or list(int) page numbers (1 indexed)\n",
    "\n",
    "    output_dir = \"./documents\" ## directory to save the consolidated markdown file\n",
    "    result = await zerox(file_path=file_path, model=model, output_dir=output_dir,\n",
    "                        custom_system_prompt=custom_system_prompt,select_pages=select_pages, **kwargs)\n",
    "    return result\n",
    "\n",
    "\n",
    "# run the main function:\n",
    "result = asyncio.run(main())\n",
    "\n",
    "# print markdown result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "## 마크다운이 생겼으니 랭체인이 제공하는 마크다운 로더를 사용해서 문서를 읽어오자.\n",
    "\n",
    "%pip install -q \"unstructured[md]\" nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "\n",
    "## pdf loader와 차이점 : pdf는 pages로 큰 문서를 알아서 쪼갰다. 페이지 단위로.\n",
    "## 마크다운은 페이지 단위로 쪼개지 않고 통으로 읽어온다. \"data = loader.load()\" 이렇게 하면 문서가 하나로 읽힌다.\n",
    "## 이럴 때는 langchain의 text splitter를 사용해서 쪼개줘야 한다.(맨 처음에 깔아줬던 패키지)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500, \n",
    "    chunk_overlap = 100,\n",
    "    separators = [\"\\n\\n\", \"\\n\"]\n",
    ")\n",
    "\n",
    "# 이렇게 해주고 그 다음 load 대신에 load_and_split 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "markdown_path = \"./documents/income_tax.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "# data = loader.load()\n",
    "# assert len(data) == 1\n",
    "# assert isinstance(data[0], Document)\n",
    "# readme_content = data[0].page_content\n",
    "# print(readme_content[:250])\n",
    "document_list = loader.load_and_split(text_splitter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list[43]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "\n",
    "# 이렇게 해주면 문서가 쪼개져서 리스트로 나온다. 그런데 표가 잘려서 안 보인다. 정확한 컨텍스트를 전달하는건 아니게 된다.\n",
    "# 이럴 때는 마크다운을 txt로 변환한 다음에 로딩을 해서 스플릿을 해줘야 한다.\n",
    "# 먼저 필요한 패키지를 설치한다.\n",
    "\n",
    "%pip install -q markdown html2text beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Read the markdown file\n",
    "text_path = './documents/income_tax.txt'\n",
    "with open(markdown_path, 'r', encoding='utf-8') as md_file:\n",
    "    md_content = md_file.read()\n",
    "\n",
    "#Convert markdown to HTML\n",
    "html_content = markdown.markdown(md_content)\n",
    "\n",
    "#use beautifulsoup to extract the text from the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "#save the text to a .txt file\n",
    "with open(text_path, 'w', encoding='utf-8') as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "print(\"Markdown converted to plain text successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.\n",
    "\n",
    "# 이제 이 텍스트를 로딩해서 스플릿을 해준다.\n",
    "# langchain_community 라이브러리에 있는 TextLoader를 사용한다.\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(text_path)\n",
    "document_list = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.\n",
    "\n",
    "#예쁘게 표가 잘 나온다.\n",
    "#크로마 DB를 만들어서 넣어준다.\n",
    "\n",
    "%pip install -q langchain_chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-openai\n",
    "%pip install -qU langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding이 필요하다.\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "# Embedding 설정\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ✅ LangChain과 호환 가능한 Embeddings 설정\n",
    "model_name = \"nlpai-lab/KURE-v1\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings_function = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어를 만들어준다.\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# ✅ 벡터 스토어 생성\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,  # 벡터화할 문서 리스트\n",
    "    embedding=embeddings_function,  # ✅ SentenceTransformer 대신 사용\n",
    "    collection_name=\"income_tax_collection\",\n",
    "    persist_directory=\"./income_tax_collection\"  # 벡터 스토어 저장 경로\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 생긴 벡터 스토어를 기반으로 retrieval을 만들어 준다.\n",
    "\n",
    "# ✅ Retrieval 객체 생성\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(\"✅ 새로운 벡터 스토어 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 질문을 해보자\n",
    "\n",
    "query = \"연봉 5천만원 직장인의 소득세는?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.\n",
    "\n",
    "# 다시 리마인드를 하면 (1)start -> (2)retrieval -> (3)genarate_answer(답변 생성) -> (4)end(return) 이렇게 된다.\n",
    "# state를 만들고 시작해보자.\n",
    "\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str # 질문\n",
    "    context: List[Document] # 컨텍스트(답변할 때 참고할 문서들: langchain의 Document 타입) - 경로는 3.1의 from langchain_core.documents import Document\n",
    "    answer: str # 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 만들어 보자.\n",
    "# 그래프 빌더를 만든다.\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드를 만든다. 두 가지가 필요하다. \n",
    "# 1. 문서를 가져오는 retrieve : 노드는 함수고 때문에 state를 인자로 받는다. \n",
    "# 2. 답변을 생성하는 generate\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    query = state['query'] # 사용자의 질문을 꺼내온다.\n",
    "    docs = retriever.invoke(query) # 질문을 활용해서 벡터스토어 우리가 만든 리트리버에 대해 검색을 한다.\n",
    "    return {'context': docs} # 검색한 문서를 state에 넣어준다. state에 보면 context가 있는 것을 확인할 수 있다. 따라서 context에 docs를 담아주는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 생성하는 generate를 만들어보자. \n",
    "#  - 기존에는 LLM에서 인보크만 했었다. 그래서 사용자 질문만 넣었다.\n",
    "#  - 이번에는 사용자 질문과 컨텍스트를 넣어줘야 한다.\n",
    "#  - rag에 효율적인 프롬프트를 작성해야 한다.\n",
    "#  - 프롬프트는 직접 작성하는 것 보다 langsmith에서 주는 프롬프트를 가져다 쓰는게 좋다.\n",
    "#  - https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=bd10098a-4810-4d31-9769-14cc090553ec\n",
    "\n",
    "# set the LANGSMITH_API_KEY environment variable (create key in settings)\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context 랑 query를 잘 받아와서, LLM을 invoke 하지 않고, 선언한 프롬프트를 활용해야한다.\n",
    "# langchain의 LCEL 문법: 파이프 활용 해서 연결하는 것. 기반으로 체인을 만들어 준다.\n",
    "\n",
    "def generate(state: AgentState):\n",
    "    query = state['query']\n",
    "    context = state['context']\n",
    "    rag_chain = prompt | llm\n",
    "    response = rag_chain.invoke({\"question\": query, \"context\": context})\n",
    "    return {'answer': response}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 연결을 시켜줘야 한다.\n",
    "#  - start -> retrieve -> generate -> end\n",
    "#  - (1) 노드 추가\n",
    "#  - (2) 엣지 추가\n",
    "\n",
    "# (1)노드 추가\n",
    "graph_builder.add_node('retrieve', retrieve)\n",
    "graph_builder.add_node('generate', generate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# START, END 임포트\n",
    "\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'retrieve')\n",
    "graph_builder.add_edge('retrieve', 'generate')\n",
    "graph_builder.add_edge('generate', END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 출력\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ※ 이렇게 시퀀스 형식인 경우에는 노드와 엣지를 일일이 그리지 않고 더 간단한 방식으로도 그래프를 그릴 수 있다.\n",
    "\n",
    "sequence_graph_builder = StateGraph(AgentState).add_sequence([retrieve, generate])\n",
    "\n",
    "# 이렇게 하면 StateGraph에 이미 위와 같은 시퀀스가 들어간 상태이다. \n",
    "# 이렇게 한 후 엣지를 한 번 추가해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_graph_builder.add_edge(START, 'retrieve') # START만 넣고 retrieve, generate는 빠진다.\n",
    "# sequence_graph_builder.add_edge('retrieve', 'generate')\n",
    "sequence_graph_builder.add_edge('generate', END)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 한 후 빌드를 한 번 해보면 그래프가 그려진다.\n",
    "\n",
    "sequence_graph = sequence_graph_builder.compile()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(sequence_graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "## 코드가 훨씬 간단해졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이제 함수를 호출해 보자\n",
    "\n",
    "initial_state = {'query': query}\n",
    "\n",
    "graph.invoke(initial_state)\n",
    "\n",
    "# 제공된 문서에는 연봉 5천만원 직장인 소득세에 대한 정보가 없다고 나온다.\n",
    "# 왜냐하면 사용자의 질문이 효율이 떨어지기 때문이다.\n",
    "# 이럴 때는 프롬프트를 수정해야 한다.\n",
    "\n",
    "# 다음 시간에 retrieve를 하고 바로 generate를 해서 답변을 생성해서 답변을 리턴하는 것이 아니라 \n",
    "# 검증을 한번 하고 문서가 사용자의 질문과 관련이 있으면 genenrate를 하고 그렇지 않으면 rewrite를 통해서 사용자의 질문을 문맥에 맡게 수정한 다음에 문서를 다시 가져오는 절차를 짚어보도록 하겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-langgraph-lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
